{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jupyter Notebook: Analysis of data from the Review, Tenure and Promotion project**\n",
    "\n",
    "*Dr. Juan Pablo Alperin, Scholarly Communications Lab*\n",
    "\n",
    "------------------\n",
    "\n",
    "This is the code used to analyze the data found in the following paper: \n",
    "\n",
    "Alperin, J., Muñoz Nieves, C., Schimanski, L., Fischman, G., Niles, M., and McKiernan, E. (2018). How significant are the public dimensions of faculty work in review, promotion, and tenure documents? *Humanities Commons [preprint]* [doi.org/10.17613/M6W950N3](https://doi.org/10.17613/M6W950N35)\n",
    "\n",
    "The input file itself can be found here: \n",
    "\n",
    "Alperin, Juan Pablo; Muñoz Nieves, Carol; Schimanski, Lesley; McKiernan, Erin C.; Niles, Meredith T., 2018, \"Terms and Concepts found in Tenure and Promotion Guidelines from the US and Canada\", [doi.org/10.7910/DVN/VY4TJE](https://doi.org/10.7910/DVN/VY4TJE), *Harvard Dataverse*, V1, UNF:6:RD6O/u5UKt8wHog/sJUx9Q== [fileUNF] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "percent_float = '{:.0f}%'.format\n",
    "normal_float = '{:.0f}'.format\n",
    "long_float = '{:.4f}'.format\n",
    "\n",
    "# Save the outputs to an excel\n",
    "writer = pd.ExcelWriter('RPT_summaries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset. Available from: https://doi.org/10.7910/DVN/VY4TJE\n",
    "df = pd.read_csv('RPT_final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some columns are descriptors, the rest are categories of interest\n",
    "descriptors = ['level', 'country', 'inst_type', 'inst_subtype', 'uni_name', 'label', 'discipline']\n",
    "categories = [x for x in df.columns if x not in descriptors]\n",
    "    \n",
    "# make a list of the first four to do some combined analysis\n",
    "output_types = [x for x in categories if 'output_type_' in x and 'generic' not in x]\n",
    "output_types_traditional = [x for x in output_types if 'performances' not in x and 'exhibitions' not in x]\n",
    "\n",
    "publication_venues = [x for x in categories if 'publication_venue_' in x ]\n",
    "\n",
    "metrics = [x for x in categories if 'metrics_' in x]\n",
    "\n",
    "peer_reviews = [x for x in categories if 'peer_review_' in x]\n",
    "\n",
    "impact_factor = [x for x in categories if 'if_' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate some metrics\n",
    "df['any_metric'] = df[metrics].apply(lambda x: x.any(), axis=1)\n",
    "df['any_output_type'] = df[output_types].apply(lambda x: x.any(), axis=1)\n",
    "df['any_output_type_traditional'] = df[output_types].apply(lambda x: x.any(), axis=1)\n",
    "df['any_publication_venue'] = df[publication_venues].apply(lambda x: x.any(), axis=1)\n",
    "df['any_peer_review'] = df[peer_reviews].apply(lambda x: x.any(), axis=1)\n",
    "\n",
    "# remove the metrics_ from the list now that they are integrated\n",
    "# categories = list(set(categories).difference(metrics)) \n",
    "categories += ['any_metric', 'any_output_type', 'any_output_type_traditional', 'any_publication_venue', 'any_peer_review']\n",
    "\n",
    "# Considering mentions of IF and of High Impact Journals together\n",
    "df['any_impact_factor'] = df[['metrics_impact_factor', 'metrics_high_impact_journals']].apply(lambda x: x.any(), axis=1)\n",
    "categories += ['any_impact_factor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any nulls, means we did not have document\n",
    "# Currently only drops Harvard University institutional-level doc\n",
    "df = df[~df[categories[0]].isnull()]\n",
    "\n",
    "df = df[descriptors].join(df[categories].astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new DF for mentions in UN, AU, UN or AU, AU but not UN (aggregations)\n",
    "uni_or_au = df.groupby('uni_name').agg(lambda x: x.any())  # UN or at least one AU\n",
    "print(len(uni_or_au))\n",
    "\n",
    "uni = df[df.level == 'UN'] # UN only\n",
    "print(len(uni))\n",
    "\n",
    "au = df[df.level == 'AU'] # AUs all (AU-level analysis)\n",
    "print(len(au))\n",
    "\n",
    "# at least one AU\n",
    "au_uni = au.groupby('uni_name').agg(lambda x: x.any())  # returns 60 institutions\n",
    "au_uni = uni[descriptors].set_index('uni_name').join(au_uni[categories]) # has all 129\n",
    "print(len(au_uni))\n",
    "\n",
    "# at least one AU and NOT at UN level\n",
    "au_not_uni = uni.set_index('uni_name').join(au_uni[categories], lsuffix='_un', rsuffix='_au')\n",
    "for cat in categories:\n",
    "    au_not_uni[cat] = au_not_uni[cat+'_un'] & au_not_uni[cat+'_au']\n",
    "    del au_not_uni[cat+'_un']\n",
    "    del au_not_uni[cat+'_au']\n",
    "print(len(au_not_uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_categories(df, name = 'n', multiply=False):\n",
    "    tmp = df[categories].sum() #.divide(len(df))\n",
    "    tmp.name = name\n",
    "    tmp_df = pd.DataFrame(tmp)\n",
    "\n",
    "    if multiply:\n",
    "        m=100\n",
    "    else:\n",
    "        m=1\n",
    "    tmp_df[tmp.name + '_p'] = tmp.divide(len(df)/m)\n",
    "    return tmp_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = normal_float\n",
    "\n",
    "# Produce a sheet that has all the above\n",
    "final = summarize_categories(uni_or_au, 'UN+AUs uni level').join(\n",
    "        summarize_categories(uni, 'UN uni level')).join(\n",
    "        summarize_categories(au_uni, 'AUs uni level')).join(\n",
    "        summarize_categories(au_not_uni, 'AUs not UN, uni level')).join(\n",
    "        summarize_categories(au, 'AUs au level'))\n",
    "# final.multiply(100)\n",
    "final.to_clipboard()\n",
    "\n",
    "final.to_excel(writer, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = normal_float\n",
    "x = uni_or_au.groupby('inst_type')\n",
    "\n",
    "print(x.size())\n",
    "y = x.sum().transpose()\n",
    "y.loc['N'] = x.size().tolist()\n",
    "y = y.reindex(['N'] + sorted([c for c in y.index if c != 'N']))\n",
    "cols = sorted(y.columns, reverse=True)\n",
    "\n",
    "cols = sorted(y.columns, reverse=True)\n",
    "print_cols = []\n",
    "for c in cols: \n",
    "    p_col = \"%s_p\" % c\n",
    "    y[p_col] = y[c]/x.size()[c]\n",
    "    print_cols += [c, p_col]\n",
    "# print(x.sum().transpose()['R1'].divide(2))\n",
    "# x.sum().transpose().to_clipboard()\n",
    "y[print_cols].to_clipboard()\n",
    "print(y[sorted(cols, reverse=True)])\n",
    "y[print_cols].to_excel(writer, \"inst_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = normal_float\n",
    "x = uni_or_au[uni_or_au.inst_subtype.isin(['R1', 'R2', 'R3', 'U15'])].groupby('inst_subtype')\n",
    "print(x.size())\n",
    "y = x.sum().transpose()\n",
    "\n",
    "y.loc['N'] = x.size().tolist()\n",
    "y = y.reindex(['N'] + sorted([c for c in y.index if c != 'N']))\n",
    "\n",
    "cols = sorted(y.columns, reverse=True)\n",
    "print_cols = []\n",
    "for c in cols: \n",
    "    p_col = \"%s_p\" % c\n",
    "    y[p_col] = y[c]/x.size()[c]\n",
    "    print_cols += [c, p_col]\n",
    "# print(x.sum().transpose()['R1'].divide(2))\n",
    "# x.sum().transpose().to_clipboard()\n",
    "y[sorted(y.columns)].to_clipboard()\n",
    "print(y[cols])\n",
    "y[print_cols].to_excel(writer, \"inst_subtype (R-types)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disciplines at the academic unit level\n",
    "# Get only R-type\n",
    "\n",
    "print(\"R-type only\")\n",
    "print(\"-----------\")\n",
    "x = au[au.inst_type == 'R-type'].groupby(['uni_name', 'discipline']).agg(lambda x: x.any())  # returns 60 institutions\n",
    "x.index = x.index.droplevel(0)\n",
    "x = x.reset_index().groupby('discipline')\n",
    "\n",
    "print(x.size())\n",
    "y = x.sum().transpose()\n",
    "y.loc['N'] = x.size().tolist()\n",
    "y = y.reindex(['N'] + sorted([c for c in y.index if c != 'N']))\n",
    "\n",
    "cols = sorted(y.columns, reverse=True)\n",
    "print_cols = []\n",
    "for c in cols: \n",
    "    p_col = \"%s_p\" % c\n",
    "    y[p_col] = y[c]/x.size()[c]\n",
    "    print_cols += [c, p_col]\n",
    "# print(x.sum().transpose()['R1'].divide(2))\n",
    "# x.sum().transpose().to_clipboard()\n",
    "y[print_cols].to_clipboard()\n",
    "print(y[sorted(cols, reverse=True)])\n",
    "\n",
    "y[print_cols].to_excel(writer, \"disciplines (R-types)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these summaries\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to cross any two categoreis\n",
    "\n",
    "pd.options.display.float_format = percent_float\n",
    "cat1 = 'any_metric'\n",
    "cat2 = 'public_and/or_community_engagement'\n",
    "\n",
    "df = uni_or_au[uni_or_au.inst_type == 'R-type']\n",
    "df2 = df[[cat1, cat2]]\n",
    "df2 = pd.crosstab(df2[cat1], df2[cat2]) # .apply(lambda x: round(x*100/len(df2)))\n",
    "df2.to_clipboard()\n",
    "print(df2)\n",
    "print('------------')\n",
    "print(\"N=%s\" % len(df))\n",
    "print(\"%s == TRUE: %s; FALSE == %s\" % (cat1, df[cat1].sum(), len(df)-df[cat1].sum()))\n",
    "print(\"%s == TRUE: %s; FALSE == %s\" % (cat2, df[cat2].sum(), len(df)-df[cat2].sum()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
